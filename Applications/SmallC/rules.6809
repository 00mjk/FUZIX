#
#	Eliminate pointless branches
#
lbra %1
%1:
=
%1:

#
#	Reverse branches to optimize
#
lbeq %1
lbra %2
%1:
=
lbne %2
%1:

lbne %1
lbra %2
%1:
=
lbeq %2
%1:

#
#	Fix up the stack based add and subtraction
#	generated by scc
#
ldd %1
pshs d
ldd %2
addd ,s++
=
ldd %1
addd %2

ldd %1
pshs d
ldd %2
subd ,s++
coma
comb
addd #1
=
ldd %1
subd %2

#
#	Post increment load into d or b via u. Relies on the fact that
#	the base compiler won't generate an std ,u in this pattern
#
ldd %1
addd #2
std %1
subd #2
tfr d,u
ldd ,u
=
ldu %1
ldd ,u++
stu %1

ldd %1
addd #1
std %1
subd #1
tfr d,u
ldb ,u
=
ldu %1
ldb ,u++
stu %1

#
#	FIXME: make sure the assembler can cope with a+b+c,s
#
ldd %1,s
addd #1
std %1,s
subd #1
pshs d
=
ldd %1,s
pshs d
addd #1
std %{%1+2},s

#
#	Commonly occuring string case
#	Could do for all values in -128 to +127 but not nice way
#	I can see to specify that in copt until I hack copt 8)
#	Should do ne cases FIXME
#

ldb %1
sex
cmpd #0
lbeq %2
ldd %3
=
ldb %1
cmpb #0
lbeq %2
ldd %3


#
#	Commonly occuring string case
#	Could do for all values in 0 to 255 but not nice way
#	I can see to specify that in copt until I hack copt 8)
#

ldb %1
clr a
cmpd #0
lbeq %2
ldd %3
=
ldb %1
cmpb #0
lbeq %2
ldd %3

#
#	Ditto but after the ,u++ optimization
#

ldb %1
stu %2
sex
cmpd #0
lbeq %3
ldd %4
=
ldb %1
stu %2
cmpb #0
lbeq %3
ldd %4


#
#	Commonly occuring string case
#	Could do for all values in 0 to 255 but not nice way
#	I can see to specify that in copt until I hack copt 8)
#

ldb %1
stu %2
clr a
cmpd #0
lbeq %3
ldd %4
=
ldb %1
stu %2
cmpb #0
lbeq %3
ldd %4
